---
layout: post
title: From Big-O to lim sup
---
The definition is little-o is often described in terms of taking a limit and checking is it is equal to zero. On the other hand, the definition of big-O is usually expressed in terms of the existence or certain positive constants satisfying an inequality. The limit definition for little-o is very useful and it would be nice if we had a similar definition for big-O. Let's see what the issues are here. Let's start with the definition of big-O,

$$f(n)$$ is $$O(g(n))$$ if there exist positive constants $$c$$ and $$N$$, such that for all $$n \geq N$$, \\[f(n) \leq cg(n)\\] Contrast this with the definition of little-o,

$$f(n)$$ is $$O(g(n))$$ if for all $$c > 0$$, there exist $$N$$, such that for all $$n \geq N$$, \\[f(n) \leq cg(n)\\]

*Note that in the definition of little-o, $$N$$ may depend on the choice of $$c$$.*
An equivalent definition of little-o is,

$$f(n)$$ is $$o(g(n))$$ if
{% raw %}
$$
\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 0
$$
{% endraw %}

This is the definition most often used for checking if $$f(n)$$ is $$o(g(n))$$, since we can apply the tools of calculus to calculate the limit instead of trying to find an $$N$$ for each $$c$$. Do we have a similar definition of big-O? It may seem at first that the following definition is equivalent to the above definition for big-O,

$$f(n)$$ is $$O(g(n))$$ if,
{% raw %}
$$
\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} < \infty
$$
{% endraw %}

The problem though is that the limit is not guaranteed to exist. This was not a problem in our definition of little-o, since in order for the limit to be $$0$$ it has to exit. Here is an example of where the limit does not exit. Take $$f(n)$$ to be the function on the integers $${0,1, \ldots, \infty}$$ such that $$f(n)=0$$ if $$n$$ is even and $$f(n)=1$$ if $$n$$ is odd.
